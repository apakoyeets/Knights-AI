ğŸ® Just taught an AI how to play the game of **Nim** â€” from scratch! ğŸ¤–

Over the past week, I built a reinforcement learning model that uses **Q-learning** to master Nim â€” a classic strategy game where players remove objects from piles, and the one forced to take the last object loses.

Hereâ€™s how it works:

ğŸ§  The AI:
- Represents the game state as pile configurations (like `[1, 3, 5, 7]`)
- Chooses actions using an **epsilon-greedy policy** (explore vs. exploit)
- Updates its strategy using the **Q-learning** algorithm:
  
  `Q(s, a) â† Q(s, a) + Î± * (reward + max Q(sâ€™, aâ€™) âˆ’ Q(s, a))`

ğŸ“ˆ After training on 10,000 games, the AI becomes nearly unbeatable!

ğŸ’¡ What I learned:
- How to implement Q-learning from scratch
- How to model turn-based strategy games with reinforcement learning
- How to tune hyperparameters like learning rate, exploration rate, etc.

ğŸ“‚ Tech stack: Python, NumPy, object-oriented programming

ğŸ•¹ï¸ Want to try beating the AI? Check out the project here:
ğŸ”— [GitHub repo link]

#AI #ReinforcementLearning #Qlearning #MachineLearning #Python #OpenSource #GameAI
